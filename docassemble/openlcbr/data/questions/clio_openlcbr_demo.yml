features:
  javascript: list_collapse.js
  css: list_collapse.css
---
modules:
  - .lcbr_explain
  - .ibp_explain
  - .ibp_data
  - docassemble.base.util
  - .DATree
  - .DAClio
---
objects:
  - database: DAStaticFile.using(filename="data/sources/trade_secret_cases.yaml")
  - reasoner: DAIBPData
  - explanation: DATree
  - test_case: DAIBPCase
---
initial: True
code: |
  process_action()

---
mandatory: True
code: |
  reasoner.load(database)
  # This is the ID for the Trade Secret practice area on the test Clio site
  # It will need to be changed if you are running against a different Clio service.
  trade_secrets = 13144306
  intro_seen
  use_custom_data
  if not use_custom_data:
    for k,v in custom_fields.iteritems():
      if v:
        test_case.factors[reasoner.get_factor_id_by_proposition(k)] = v
    test_case.factors.gathered = True
  else:
    # Deleting the test_case.factors attribute forces the interview to collect it again.
    del test_case.factors
---
question: docassemble-openlcbr demo
subquestion: |
  This website is a demonstration of the docassemble-openlcbr package being developed
  by Jason Morris of Round Table Law as an ABA Innovation Fellowship project for
  2018/2019.  The fellowship is sponsored by [Clio](http://www.clio.com).
  
  The project is to take openlcbr, which is an open-source tool for
  legal case-based reasoning written by Matthias Grabmair, and to implement it as a
  extension to docassemble.
  
  [Docassemble](https://docassemble.org) is a leading open-source legal expert system and document automation
  platform written by Jonathan Pyle.
  
  The purpose of the project is to explore whether it is possible to use
  reasoning-by-analogy to extend the capabilities of legal expert systems to
  include answering open-textured legal questions.
field: intro_seen
---
question: Choose a Data Source
subquestion: |
  Docassemble can be configured to use data located in your law firm's practice
  management software.
  
  Would you like to run the analogical reasoning tool against
  a case that you describe, or would you like to select a matter from a demonstration
  Clio service?
field: use_custom_data
buttons:
  - "Choose an Open Clio Matter": False
  - "Enter Case Details": True
---
if: use_custom_data == True
question: Which of the following factors apply to the test case?
fields:
  - no label: test_case.factors
    datatype: checkboxes
    code: reasoner.factorslist
---
generic object: DATree
code: |
  # This is required when DATree is being used for elements generated by code.
  x.branches.there_is_another = False
---
if: use_custom_data == False
question: Which Clio Matter Do You Want to Predict?
subquestion: |
  This interface is communicating with Clio via API to obtain a list of all open
  cases in the "Trade Secrets" practice area.
fields:
  - Matter: matter
    code: matters
---
code: |
  matters = get_matters_in_pa(trade_secrets)
---
code: |
  custom_fields = get_custom_fields_in_matter(matter)
---
mandatory: True
question: |
  % if explanation.prediction == "p" or explanation.prediction == "d":
  Your issue would be decided for the ${ prediction_word(explanation.prediction) }
  % else:
  The system abstains from making a prediction.
  % endif
subquestion: |
  ${ explanation.display_tree() }
---
code: |
  explanation = reasoner.predict(test_case)
---